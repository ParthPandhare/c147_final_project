{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KpdEPoNC-Pt"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "OrPLR316D1Ps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim, utils\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "import h5py\n",
        "\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import os #file_path = \"your_file.h5\"\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3LfPVasDA7S"
      },
      "source": [
        "# Section Requiring Modification (Dataset class and Model class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkQHeMczD4mK"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "MODIFY THIS CELL TO INCLUDE YOUR OWN DATASET\n",
        "'''\n",
        "\n",
        "class customDataset (torch.utils.data.Dataset):\n",
        "    def __init__(self, path, file_names):\n",
        "        super(customDataset, self).__init__()\n",
        "\n",
        "        data1 = []\n",
        "        data2 = []\n",
        "        data3 = []\n",
        "        if (type(file_names)!=list):\n",
        "            file_names = [file_names]\n",
        "\n",
        "        for file_name in file_names:\n",
        "            with h5py.File(path + file_name, 'r') as f:\n",
        "                dataset = (f[\"emg2qwerty\"][\"timeseries\"][:])\n",
        "\n",
        "            for i, j, k in dataset:\n",
        "                data1.append(i)\n",
        "                data2.append(j)\n",
        "                data3.append(k)\n",
        "\n",
        "        self.data1 = np.array(data1)\n",
        "        self.data2 = np.array(data2)\n",
        "        self.data3 = np.array(data3)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data1)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return (self.data1[index], self.data2[index], self.data3[index])\n",
        "\n",
        "\n",
        "user = \"Sparsh\" #\"Parth\" \"Theo\" \"Rama\"\n",
        "if user==\"Sparsh\":\n",
        "    path = \"../../\"\n",
        "\n",
        "trainingData = customDataset(path,\n",
        "                             [\"2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f.hdf5\",\n",
        "                              \"2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f.hdf5\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3490549"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "fQGC4SOkEAi3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "MODIFY THIS CELL TO INCLUDE YOUR OWN MODEL\n",
        "'''\n",
        "\n",
        "class model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(model, self).__init__()\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "myModel = model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e2e76-kC1ZM"
      },
      "source": [
        "# Training and Evaluation Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D56HwNRsEGrt"
      },
      "outputs": [],
      "source": [
        "def trainingLoop(modeltoTrain, trainData, lossFunc, optimizer, EPOCHS, BATCH_SIZE, preprocessing = lambda x: x):\n",
        "  modeltoTrain.train()\n",
        "  for current_epoch in range(EPOCHS):\n",
        "      for batch_inputs, actualClasses in iter(torch.utils.data.DataLoader(trainData, batch_size = BATCH_SIZE, shuffle = True)):\n",
        "          predicted_outputs = modeltoTrain(preprocessing(batch_inputs))\n",
        "          currentLoss = lossFunc(predicted_outputs, actualClasses)\n",
        "          currentLoss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "def evaluationLoop(modeltoTest, trainData, BATCH_SIZE, preprocessing = lambda x: x, postprocessing = lambda x: x):\n",
        "  modeltoTest.eval()\n",
        "\n",
        "  allPreds = torch.Tensor([])\n",
        "  allAnswers = torch.Tensor([])\n",
        "\n",
        "  for current_epoch in range(EPOCHS):\n",
        "      for batch_inputs, actualClasses in iter(torch.utils.data.DataLoader(trainData, batch_size = BATCH_SIZE, shuffle = True)):\n",
        "          predicted_outputs = modeltoTest(preprocessing(batch_inputs))\n",
        "          allPreds = torch.cat([allPreds, postprocessing(predicted_outputs)])\n",
        "          allAnswers = torch.cat([allAnswers, actualClasses])\n",
        "\n",
        "  return allPreds, allAnswers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVJOGpcEEKlE"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "predictions_before_training, answers_before_training = evaluationLoop(myModel,\n",
        "                                                                      testingData,\n",
        "                                                                      BATCH_SIZE,\n",
        "                                                                      customDataset.preprocessing,\n",
        "                                                                      customDataset.postprocessing)\n",
        "\n",
        "trainingLoop(myModel,\n",
        "             trainingData,\n",
        "             nn.CrossEntropyLoss(),\n",
        "             optim.Adam(myDecoder.parameters(), lr = 0.001),\n",
        "             EPOCHS,\n",
        "             BATCH_SIZE,\n",
        "             customDataset.preprocessing)\n",
        "\n",
        "predictions_after_training, answers_after_training = evaluationLoop(myModel,\n",
        "                                                                    testingData,\n",
        "                                                                    BATCH_SIZE,\n",
        "                                                                    customDataset.preprocessing,\n",
        "                                                                    customDataset.postprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73C-qywUCt_Y"
      },
      "source": [
        "# Understanding How Well the Model Is Performing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrRcqnqKAdWa"
      },
      "outputs": [],
      "source": [
        "print(\"Before training the model...\")\n",
        "plt.imshow(metrics.confusion_matrix(predictions_before_training, answers_before_training))\n",
        "plt.show()\n",
        "print(\"After training the model...\")\n",
        "plt.imshow(metrics.confusion_matrix(predictions_after_training, answers_after_training))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJTA-3AHAolm"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "placeInBatch = random.randint(0, BATCH_SIZE-1)\n",
        "images, classes = iter(testDataLoader).__next__()\n",
        "image = images[placeInBatch]\n",
        "trueClass = classes[placeInBatch]\n",
        "\n",
        "print(\"Sample image:\")\n",
        "plt.imshow(image[0], cmap = \"gray\")\n",
        "plt.show()\n",
        "print(\"True class:\", trueClass.item())\n",
        "print(\"Prediction:\",\n",
        "      customDataset.postprocessing\n",
        "        (\n",
        "            model(\n",
        "                  customDataset.preprocessing(image)\n",
        "                 )\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC2V0y-rCpFS"
      },
      "source": [
        "# Saving and Loading Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fla_-duSCIDu"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgmum_YSCI8j"
      },
      "outputs": [],
      "source": [
        "secondModel = model()\n",
        "\n",
        "secondModel.load_state_dict(torch.load(\"model.pth\"))\n",
        "secondModel.to(device)\n",
        "secondModel.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26Mzyl8LCgAB"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "placeInBatch = random.randint(0, BATCH_SIZE-1)\n",
        "images, classes = iter(testDataLoader).__next__()\n",
        "image = images[placeInBatch]\n",
        "trueClass = classes[placeInBatch]\n",
        "\n",
        "print(\"Sample image:\")\n",
        "plt.imshow(image[0], cmap = \"gray\")\n",
        "plt.show()\n",
        "print(\"True class:\", trueClass.item())\n",
        "print(\"Prediction:\",\n",
        "      customDataset.postprocessing\n",
        "        (\n",
        "          secondModel(\n",
        "                      customDataset.preprocessing(image)\n",
        "                     )\n",
        "        )\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
